{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce945e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import unicodedata\n",
    "import random\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import islice\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5b5845",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'corpus2mw'\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7b9e9",
   "metadata": {},
   "source": [
    "# Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e71e29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "\n",
    "    text = text.replace(\"’\", \"'\").replace(\"‘\", \"'\").replace(\"−\", \"-\").replace(\"–\", \"-\").replace(\"—\", \"-\")\n",
    "\n",
    "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r\"(?<=\\w)-(?=\\w)\", \"_\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s_']\", ' ', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de11d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.is_punct or token.is_space:\n",
    "            continue\n",
    "\n",
    "        txt = token.text.lower()\n",
    "\n",
    "        if \"_\" in txt:\n",
    "            if re.match(r'^[a-z0-9_]+$', txt):\n",
    "                tokens.append(txt)\n",
    "                \n",
    "        else:\n",
    "            lemma = token.lemma_.lower()\n",
    "            if token.pos_ == \"VERB\" or token.like_num or token.is_alpha:\n",
    "                if re.match(r'^[a-z0-9]+$', lemma): \n",
    "                    tokens.append(lemma)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "930a94d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ngrams(tokens, max_n):\n",
    "    result = Counter()\n",
    "\n",
    "    for n in range(1, max_n + 1):\n",
    "        ngrams = zip(*(islice(tokens, i, None) for i in range(n)))\n",
    "        result.update(ngrams)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff1d83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_frequency(ngrams, min_freq):\n",
    "    return {k: v for k, v in ngrams.items() if v >= min_freq and len(k) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08fe352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scp_score(ngram, ngram_counts, unigram_counts, alpha=0.01):\n",
    "    total_words = sum(unigram_counts.values())\n",
    "    vocab_size = len(unigram_counts)\n",
    "    joint_prob = (ngram_counts.get(ngram, 0) + alpha) / (total_words + alpha * vocab_size)\n",
    "    product = 1\n",
    "\n",
    "    for word in ngram:\n",
    "        p_word = (unigram_counts.get((word,), 0) + alpha) / (total_words + alpha * vocab_size)\n",
    "        product *= p_word\n",
    "\n",
    "    return (joint_prob ** 2) / product if product != 0 else 0\n",
    "\n",
    "\n",
    "def dice_score(ngram, ngram_counts, unigram_counts):\n",
    "    f_ngram = ngram_counts[ngram]\n",
    "    f_sum = sum(unigram_counts.get((w,), 0) for w in ngram)\n",
    "\n",
    "    return (len(ngram) * f_ngram) / f_sum if f_sum else 0\n",
    "\n",
    "\n",
    "def phi2_score(ngram, ngram_counts, unigram_counts):\n",
    "    O = ngram_counts[ngram]\n",
    "    N = sum(unigram_counts.values())\n",
    "    E = 1\n",
    "\n",
    "    for w in ngram:\n",
    "        E *= unigram_counts.get((w,), 1) / N\n",
    "\n",
    "    E *= N\n",
    "\n",
    "    return ((O - E) ** 2) / E if E else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f82f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_local_max(ngram, scores, ngram_counts):\n",
    "    n = len(ngram)\n",
    "    score = scores.get(ngram, 0)\n",
    "\n",
    "    for i in range(n):\n",
    "        sub_ngram = ngram[:i] + ngram[i+1:]\n",
    "        if sub_ngram in scores and scores[sub_ngram] > score:\n",
    "            return False\n",
    "\n",
    "    for other_ngram in scores.keys():\n",
    "        if len(other_ngram) == n + 1:\n",
    "\n",
    "            for j in range(len(other_ngram) - n + 1):\n",
    "                if other_ngram[j:j+n] == ngram and scores[other_ngram] > score:\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def extract_local_max(scores, ngram_counts, min_len=2):\n",
    "    local_max_ngrams = {}\n",
    "\n",
    "    for ngram in scores:\n",
    "        if len(ngram) >= min_len and is_local_max(ngram, scores, ngram_counts):\n",
    "            local_max_ngrams[ngram] = scores[ngram]\n",
    "\n",
    "    return local_max_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f7b5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_candidates(directory, max_files=None):\n",
    "    all_candidates = set()\n",
    "    \n",
    "    files = sorted([f for f in os.listdir(directory) if f.startswith('fil_')],\n",
    "                  key=lambda x: int(x.split('_')[1]))\n",
    "    \n",
    "    if max_files:\n",
    "        files = files[:max_files]\n",
    "    \n",
    "    for filename in tqdm(files, desc=\"Processing Files\"):\n",
    "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as f:\n",
    "            original = f.read()\n",
    "        \n",
    "        preprocessed = preprocess_text(original)\n",
    "        tokens = tokenize(preprocessed)\n",
    "        unigrams = extract_ngrams(tokens, 1)\n",
    "        ngrams = extract_ngrams(tokens, 7)\n",
    "        filtered = filter_by_frequency(ngrams, 2)\n",
    "        \n",
    "        scp_scores = {ng: scp_score(ng, filtered, unigrams) for ng in filtered}\n",
    "        dice_scores = {ng: dice_score(ng, filtered, unigrams) for ng in filtered}\n",
    "        phi2_scores = {ng: phi2_score(ng, filtered, unigrams) for ng in filtered}\n",
    "        \n",
    "        sorted_scp_scores = dict(sorted(scp_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "        sorted_dice_scores = dict(sorted(dice_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "        sorted_phi2_scores = dict(sorted(phi2_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "        localmax_scp = extract_local_max(sorted_scp_scores, filtered)\n",
    "        localmax_dice = extract_local_max(sorted_dice_scores, filtered)\n",
    "        localmax_phi2 = extract_local_max(sorted_phi2_scores, filtered)\n",
    "        \n",
    "        for method in [localmax_scp, localmax_dice, localmax_phi2]:\n",
    "            for ngram in method:\n",
    "                all_candidates.add(' '.join(ngram))\n",
    "    \n",
    "    return sorted(all_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b910e0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 3170/3170 [05:59<00:00,  8.82it/s]\n"
     ]
    }
   ],
   "source": [
    "candidates = collect_all_candidates(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06450139",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b28c4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_evaluation(candidates, sample_size, random_seed=42):\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    return random.sample(candidates, min(sample_size, len(candidates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bebf45fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_sample = precision_evaluation(candidates, 50)\n",
    "\n",
    "with open('precision_sample.txt', 'w', encoding='utf-8') as f:\n",
    "    for i, mwe in enumerate(precision_sample, 1):\n",
    "        f.write(f\"{mwe}\\n\")\n",
    "\n",
    "# after the creation of the precision sample file we need to edit it manually\n",
    "# writting TP (valid) or FP (not valid) for each relevant expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac215fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(file):\n",
    "    valid = 0\n",
    "    total = 0\n",
    "    \n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip().endswith('TP'):\n",
    "                valid += 1\n",
    "            total += 1\n",
    "    \n",
    "    return valid / total if total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0d2fe6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_precision('precision_sample.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493446ec",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2841aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paragraphs(directory, num_paragraphs, max_files=None):\n",
    "    files = sorted([f for f in os.listdir(directory) if f.startswith('fil_')],\n",
    "                  key=lambda x: int(x.split('_')[1]))\n",
    "    \n",
    "    if max_files:\n",
    "        files = files[:max_files]\n",
    "    \n",
    "    all_paragraphs = []\n",
    "    \n",
    "    for filename in files:\n",
    "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "        all_paragraphs.extend(paragraphs)\n",
    "    \n",
    "    return random.sample(all_paragraphs, min(num_paragraphs, len(all_paragraphs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "116ae739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph 1:\n",
      "<doc id=\"14717782\" url=\"http://en.wikipedia.org/wiki?curid=14717782\" title=\"Setenyovo\">\n",
      "On November 23, 1999 Iowa State didn't receive any votes in the USA Today/ESPN Top 25 coaches poll. They also were ranked T–47th in the AP Top 25 poll with 2 points. From November 26 – November 28 the Cyclones participated in the Big Island Invitational at Hilo Hawai'i. From December 3 – December 4 the Cyclones hosted the Norwest Cyclone Challenge. From December 21 – December 22 the Cyclones hosted the Tribune Holiday Classic. On December 14, 1999 Iowa State didn't receive any votes in the USA Today/ESPN Top 25 coaches poll. They also were ranked T–47th in the AP Top 25 poll with 1 point. On December 21, 1999 Iowa State didn't receive any votes in the USA Today/ESPN Top 25 coaches poll. They also were ranked T–46th in the AP Top 25 poll with 1 point. On December 28, 1999 Iowa State didn't receive any votes in the USA Today/ESPN Top 25 coaches poll. They also were ranked T–39th in the AP Top 25 poll with 6 points. On January 4, 2000 Iowa State didn't receive any votes in the USA Today/ESPN Top 25 coaches poll. They also were ranked T–39th in the AP Top 25 poll with 6 points. On January 11, 2000 Iowa State received 1 point in the USA Today/ESPN Top 25 coaches poll which had them ranked T–47th. They also were ranked 30th in the AP Top 25 poll with 26 points. On January 18, 2000 Iowa State received 6 points in the USA Today/ESPN Top 25 coaches poll which had them ranked T–39th. They also were ranked 29th in the AP Top 25 poll with 56 points. On January 25, 2000 Iowa State received 20 points in the USA Today/ESPN Top 25 coaches poll which had them ranked 29th. They also were ranked 28th in the AP Top 25 poll with 49 points. On February 1, 2000 Iowa State received 76 points in the USA Today/ESPN Top 25 coaches poll which had them ranked 24th. They also were ranked 20th in the AP Top 25 poll with 331 points. On February 8, 2000 Iowa State received 115 points in the USA Today/ESPN Top 25 coaches poll which had them ranked 21st. They also were ranked 17th in the AP Top 25 poll with 519 points. On February 15, 2000 Iowa State received 277 points in the USA Today/ESPN Top 25 coaches poll which had them ranked 17th. They also were ranked 14th in the AP Top 25 poll with 811 points. On February 22, 2000 Iowa State received 229 points in the USA Today/ESPN Top 25 coaches poll which had them ranked 18th. They also were ranked 17th in the AP Top 25 poll with 662 points. On February 29, 2000 Iowa State received 353 points in the USA Today/ESPN Top 25 coaches poll which had them ranked 14th. They also were ranked 10th in the AP Top 25 poll with 1,045 points. The time of the March 4, 2000 Baylor game was changed from 7:00 p.m. CST to 6:00 p.m. CST. On March 4, 2000 Iowa State clinched their first conference title since 1945 with a 75–54 win over Baylor.\n",
      "Wolfern is a municipality in the district of Steyr-Land in the Austrian state of Upper Austria.\n",
      "==================================================\n",
      "\n",
      "Paragraph 2:\n",
      "Upon the album's reissue in 2000, \"Alternative Press\" gave \"Get Up with It\" a rave review and called it \"essential ... the overlooked classic of psychedelic soul and outlandish improv ... representing the high water mark of [Davis'] experiments in the fusion of rock, funk, electronica and jazz\". Stylus Magazine's Chris Smith said that it is \"not an easy album to write, let alone think, about. It’s a bit more of an anything-goes hodgepodge than it is a sprawling masterwork, and is probably written about the least of all Miles’ electric work.\"\n",
      "The twins consider their job done and grant their father's wish of having a burial at sea with the assistance of Bryn's boat, with the coffin respectfully draped in the Welsh flag. It is a poignant moment as the local choir (formed from a number of real-life local male voice choirs) sing the Welsh language song \"Myfanwy\" at the end of Mumbles Pier. Meanwhile Terry Walsh, terrified and pleading, has been gagged and bound to the coffin, and lowered into the sea just off the pier head of Mumbles Swansea. The coffin floats for a while before the twins make a bet to how long the coffin would stay afloat, seemingly brushing aside the emotion of their father's funeral at sea.\n",
      "History.\n",
      "History.\n",
      "==================================================\n",
      "\n",
      "Paragraph 3:\n",
      "T-type calcium channels are involved in diseases such as absence epilepsy, diabetes, and several forms of cancer.\n",
      "Åsa Domeij, born 29 April 1962 in Örnsköldsvik, is a Swedish Green Party politician and an agronomist by training. She was a member of the Riksdag from 1988 until 1991 and then again from 2002 until 2006.\n",
      "==================================================\n",
      "\n",
      "Paragraph 4:\n",
      "The Rain Bird horizontal action impact drive sprinkler head was recognized as a historic landmark of agricultural engineering in 1990 by the American Society of Agricultural Engineers. This invention led to sprinkler irrigation development that currently exceeds 50 million acres worldwide. Other products that have received this award include Eli Whitney's cotton gin.\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paragraphs_sample = extract_paragraphs(directory, 4)\n",
    "\n",
    "for i, para in enumerate(paragraphs_sample, 1):\n",
    "    print(f\"Paragraph {i}:\\n{para}\\n{'='*50}\\n\")\n",
    "\n",
    "# after getting the sample paragraphs, we need to create a file recall_sample.txt\n",
    "# writting the relevant expressions found in each paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f62df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(file, system_candidates):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        manual_mwes = set(line.strip() for line in f if line.strip())\n",
    "    \n",
    "    system_mwes = set(' '.join(ngram) for ngram in system_candidates)\n",
    "    \n",
    "    matches = 0\n",
    "    for mwe in manual_mwes:\n",
    "        if mwe.lower() in system_mwes:\n",
    "            matches += 1\n",
    "    \n",
    "    return matches / len(manual_mwes) if manual_mwes else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc55ddf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_recall('recall_sample.txt', candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa3649",
   "metadata": {},
   "source": [
    "# Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c0ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_most_informative(localmax_scores, top_n=15):\n",
    "    sorted_res = sorted(\n",
    "        localmax_scores.items(),\n",
    "        key=lambda x: (x[1], len(x[0])),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    return sorted_res[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c92c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(ngram_sets):\n",
    "    all_res = list(set(' '.join(ng) for ngrams in ngram_sets for ng in ngrams))\n",
    "    \n",
    "    doc_texts = [' '.join(' '.join(ng) for ng in ngrams) for ngrams in ngram_sets]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split())\n",
    "    tfidf_matrix = vectorizer.fit_transform(doc_texts + all_res)\n",
    "\n",
    "    re_matrix = tfidf_matrix[-len(all_res):]\n",
    "    similarity = cosine_similarity(re_matrix)\n",
    "\n",
    "    return {\n",
    "        all_res[i]: {\n",
    "            all_res[j]: similarity[i][j] for j in range(len(all_res)) if i != j\n",
    "        } for i in range(len(all_res))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cca7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_implicit_keywords(explicit_keywords, similarity_matrix, threshold=0.3, top_n=5):\n",
    "    implicit_keywords = set()\n",
    "    \n",
    "    for ek in explicit_keywords:\n",
    "        ek = ek.lower()\n",
    "        if ek not in similarity_matrix:\n",
    "            continue\n",
    "        \n",
    "        similar = similarity_matrix.get(ek, {})\n",
    "        candidates = [(re, sim) for re, sim in similar.items() if sim >= threshold and re != ek]\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for re, _ in candidates[:top_n]:\n",
    "            implicit_keywords.add(re)\n",
    "    \n",
    "    return list(implicit_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb9ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents_for_keywords(directory, num_files=None):\n",
    "    files = sorted([f for f in os.listdir(directory) if f.startswith('fil_')],\n",
    "                  key=lambda x: int(x.split('_')[1]))\n",
    "    \n",
    "    if num_files:\n",
    "        files = files[:num_files]\n",
    "    \n",
    "    all_documents = []\n",
    "    all_explicit_keywords = []\n",
    "    all_ngrams = []\n",
    "    \n",
    "    for filename in tqdm(files, desc=\"Extracting REs\"):\n",
    "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as f:\n",
    "            original = f.read()\n",
    "        \n",
    "        preprocessed = preprocess_text(original)\n",
    "        tokens = tokenize(preprocessed)\n",
    "        unigrams = extract_ngrams(tokens, 1)\n",
    "        ngrams = extract_ngrams(tokens, 7)\n",
    "        filtered = filter_by_frequency(ngrams, 2)\n",
    "        \n",
    "        scp_scores = {ng: scp_score(ng, filtered, unigrams) for ng in filtered}\n",
    "        dice_scores = {ng: dice_score(ng, filtered, unigrams) for ng in filtered}\n",
    "        phi2_scores = {ng: phi2_score(ng, filtered, unigrams) for ng in filtered}\n",
    "\n",
    "        sorted_scp_scores = dict(sorted(scp_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "        sorted_dice_scores = dict(sorted(dice_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "        sorted_phi2_scores = dict(sorted(phi2_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "        \n",
    "        localmax_scp = extract_local_max(sorted_scp_scores, filtered)\n",
    "        localmax_dice = extract_local_max(sorted_dice_scores, filtered)\n",
    "        localmax_phi2 = extract_local_max(sorted_phi2_scores, filtered)\n",
    "        \n",
    "        combined_localmax = {}\n",
    "        for method in [localmax_scp, localmax_dice, localmax_phi2]:\n",
    "            for ng, score in method.items():\n",
    "                key = ' '.join(ng)\n",
    "                if key not in combined_localmax or score > combined_localmax[key]:\n",
    "                    combined_localmax[key] = score\n",
    "        \n",
    "        informative_res = select_most_informative(combined_localmax)\n",
    "        \n",
    "        all_documents.append({\n",
    "            'filename': filename,\n",
    "            'original': original,\n",
    "            'preprocessed': preprocessed,\n",
    "            'tokens': tokens,\n",
    "            'localmax': combined_localmax,\n",
    "            'informative_res': informative_res\n",
    "        })\n",
    "        \n",
    "        all_ngrams.append(set(tuple(kw.split()) for kw in combined_localmax.keys()))\n",
    "        all_explicit_keywords.append([(kw, score) for kw, score in informative_res])\n",
    "    \n",
    "    similarity_matrix = calculate_similarity_matrix(all_ngrams)\n",
    "    \n",
    "    for i, doc in enumerate(all_documents):\n",
    "        explicit_keywords = [ek[0] for ek in all_explicit_keywords[i]]\n",
    "        implicit_keywords = find_implicit_keywords(\n",
    "            explicit_keywords, \n",
    "            similarity_matrix\n",
    "        )\n",
    "        \n",
    "        doc['explicit_keywords'] = explicit_keywords\n",
    "        doc['implicit_keywords'] = implicit_keywords\n",
    "    \n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b24ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_with_keywords = process_documents_for_keywords(directory, num_files=1)\n",
    "    \n",
    "for doc in documents_with_keywords:\n",
    "    print(f\"\\nDocument: {doc['filename']}\")\n",
    "\n",
    "    print(\"\\nAll Local Maxs (REs):\")\n",
    "    for i, (kw, score) in enumerate(sorted(doc['localmax'].items(), key=lambda x: -x[1]), 1):\n",
    "        print(f\"{i}. {kw} (score: {score:.4f})\")\n",
    "\n",
    "    print(\"\\nExplicit Keywords (Top Informative REs):\")\n",
    "    for i, (kw, score) in enumerate(doc['informative_res'], 1):\n",
    "        print(f\"{i}. {kw} (score: {score:.4f})\")\n",
    "    \n",
    "    print(\"\\nImplicit Keywords (Similarity-Based):\")\n",
    "    for i, kw in enumerate(doc['implicit_keywords'], 1):\n",
    "        print(f\"{i}. {kw}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
